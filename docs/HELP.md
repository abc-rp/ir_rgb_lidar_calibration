### ISSUES

------

#### Q1: The feature detection in camera failed (step 3.2).

1. Confirm the calibration board's color matched what was set during the execution of start_up.bash (`darkBoard` or `whiteBoard`)
2. Ensure enough board-background contrast.
3. Watch for board reflections in reflective environments (especially for the thermal camera)
4. In the case of the IR cameras, when running the `colourmap_real_time.py` script, it is possible to vary the contrast threshold (between 0-255)to further isolate the board using:
```shell
rosparam set /thermal_image_colormap_dual/threshold 120
```
Here, the threshold was set to a value of 120, which is a reasonable starting value.
5. In the case of the RGB cameras, it may be useful or necessary to adjust the exposure. By default, on the BESS, this is a fixed value. It can be modified to isolate the target or reverted to be automatic.

#### Q2: The board detetcion in LiDAR failed (step 3.2)

1. **The LiDAR intensity differs from code presets**. Check LiDAR's row point cloud in Rviz for intensity on the calibration board (assumed as *n*) and on the poster support (assumed as *m*). Typically, *m*<*n*. Run

   ```shell
   rosrun rqt_reconcfigure rqt_reconcfigure
   ```

   find the `(ns_lidar)/laser_pattern` node and adjust '*i_filter_out_max*' value between *m* and *n*, until the detected calibration board is successfully shown in Rviz.

2. The preset clustering parameters are not suitable, which can happen when **the clustering 'min size' threshold is set too low**, leading to the filtering out of the calibration board point cloud. This situation often occurs when calibrating sparse lidars like Velodyne VLP-16. Please adjust the value of '*cluster_size_min*' based on the actual situation. 

   (Note: this value is not a specific point cloud size but a ratio.)

3. (Not recommend to prioritize) The threshold for board detection is too strict. You can adjust the values of '*rmse_ukn2tpl_thre*' and '*rmse_tpl2ukn_thre*'. The larger these values are, the more lenient the detection criteria become. However, please note that these values will affect the accuracy of board detection. It is recommended to adjust them in the range of [0.02, 0.05].

   

#### Q3: The feature collection takes too long (step 3.3)

1. The default number of collection frame in the code is 60 frames, which has been found to be optimal through experiments. This is not the framerate of capture but rather the number of frames required for the capture of a given target position to be complete. You can reduce this value as needed by specifying the '*maxFrame*' argument when running `start_up.bash`

   ```shell
   # set the number of collection frame as 30
   bash start_up.bash --maxFrame 30
   ```

   (Note: Reducing this variable may affect calibration accuracy)

2. The LiDAR's field of view is too large, for example, in the case of a 360-degree scanning LiDAR, resulting in too many outlier point clouds, which adds unnecessary computational burden. You can consider preprocessing the raw point cloud using tools like a passthrough filter.

### NODE STRUCTURE

------

- laser_pattern - automatic detection of the calibration target and extraction of features in LiDAR point clouds
- cam_pattern - automatic detection of the calibration target and extraction of features in images (from the thermal camera)
- pattern_collection - accumulation and collection of features extracted from LiDAR point clouds and thermal images
- extrinsic_calib - calculation of the extrinsic parameters, using minimizing 2D re-projection errors and minimizing 3D matching errors

### TOPIC DESCRIPTION

------

TBC...

### PARAMETER DESCRIPTION

------

##### Parameters in laser_pattern.launch

1. X-filed PassThrough filter: to remove the noise generated by the mirror reflection in Livox itself.

   - *remove_x_min* & *remove_x_max*: the numrical limits for x field for data to be removed.

2. vox_filter: use VoxelGrid to downsample and uniform the point cloud.

   - *use_vox_filter*: whether to use the VoxelGrid filter
   - *voxel_grid_size*: the voxel grid leaf size, as a cube (unit: m).

3. cluster: do cluster before the plane segmentation.

   - *cluster_tole*: the spatial cluster tolerance as a measure in the L2 Euclidean space (unit: m). Recommend 0.05~0.1.
   - *cluster_size_min* & *cluster_size_max*: the minimum and maximum scale of the number of points that a cluster needs to contain in order to be considered valid. Recommend *cluster_size_max* as 2~5 and match the value of *cluster_tole*.

4. gauss_filter: gaussian filter, used in automatic detection of the calibration board. Another gauss_filter2 is used to smooth the accumulated calibration board point cloud.

   - *use_gauss_filter*: whether to use the Gaussian filter

   - *gauss_k_sigma*: the sigma (standard deviation) of the Gaussian Kernel

   - *gauss_k_thre_rt_sigma*: the distance threshold relative to a sigma factor i.e. points such as pi are not considered according to the following equation.
     $$
     ||p_i-q|| > gauss\_k\_thre\_rt\_sigma^2 * sigma^2
     $$

   - *gauss_k_thre*: the distance threshold such as pi are not considered according to the following equation.
     $$
     ||p_i-q|| > gauss\_k\_thre
     $$

   - *gauss_conv_radius*: the sphere radius that is to be used for determining the nearest neighbors

5. plane segmentation: SACSegmentation

   - *Pseg_dis_thre*: the threshold of the distance to the model (user given parameter). Recommend: 0.01~0.02.
   - *iter_num*: the maximum number of iterations the sample consensus method will run.
   - *seg_size_min*: the minimum scale of the plane size (relative to the size of the cluster to which the plane belongs). Recommend: 0~0.02, matching the value of *cluster_size_max*.

6. statistic_filter: StatisticalOutlierRemoval uses point neighborhood statistics to filter outlier data.

   - *use_statistic_filter*: whether to use StatisticalOutlierRemoval filter
   - *sor_MeanK*: the number of nearest neighbors to use for mean distance estimation
   - *sor_StddevMulThresh*: the standard deviation multiplier for the distance threshold calculation

7. intensity filter: The black supporter used to support the calibration board will interfere the automatic detection of the white calibration board. The filtering is performed using the intensity difference between the black and white reflected point clouds.

   - *use_i_filter*: whether to use the intensity filter
   - *i_filter_out_min* & *i_filter_out_max*: the numerical limits for the intensity field for data to be removed. Recommend *i_filter_out_max* as 15~50.

8. boundary estimation: to estimate the surface boundary based on the normal estimation

   - *boundEstRad*: the number of k nearest neighbors to use for the boundary estimation
   - *normEstRad*: the number of k nearest neighbors to use for the normal estimation

9. template matching criterion:

   - *rmse_ukn2tpl_thre* & *rmse_ukn2tpl_thre*: the similarity threshold between the point cloud to be evaluated and the template point cloud. When values of the similarity are less than these two thresholds, the plane is judged as calibration plate point cloud. Recommend: 0.03~0.05.

10. center extraction: based on circle extraction

    - *circle_radius*: the radius for the circle model (set according to the calibration board size parameters)
    - *circle_seg_thre*: the allowable radius limits for the circle model (set according to the noise)
    - *centroid_dis_min* & *centroid_dis_max*: the numerical limits for the distance between the center of the detected circle and the centroid of the whole point cloud (set according to the calibration plate size parameters)
    - *min_centers_found*: minimum number of centers extracted (4 circle centers for the four-circle-hole plate)

##### Content in feature_info.csv

- time: the system time of feature point acquisition for this group
- detected_lv[i]x, detected_lv[i]y, detected_lv[i]z (i = 0, 1, 2, 3): <u>3D coordinates</u> (xyz-coordinates) corresponding to the 4 circle centers extracted in the <u>Livox point cloud</u>
- detected_cv[i]x, detected_cv[i]y, detected_cv[i]z (i = 0, 1, 2, 3): <u>3D coordinates</u> (xyz-coordinates) corresponding to the 4 circle centers extracted in the <u>(thermal) image</u>
- cam_2d_detected_centers[i]x, cam_2d_detected_centers[i]y (i = 0, 1, 2, 3): <u>2D coordinates</u> (pixel coordinates) corresponding to the 4 circle centers extracted in the <u>(thermal) image</u>

##### Content in extrinsic result .csv file

- pos: the serial number of the group corresponding to the feature points used in the extrinsic parameter calculation (corresponding to the serial number in the last column of the features_info.csv file)

- x, y, z, r, p, y: calculated extrinsic parameters in 6-DOF form, i.e. [x, y, z, roll, pitch, yaw]

- R0, R1, ... , R8: the components of the rotation matrix R in the extrinsic parameter matrix Tr
  $$
  R = 
  \left[
  \begin{matrix}
  R0&R1&R2\\
  R3&R4&R5\\
  R6&R7&R8\\
  \end{matrix}
  \right]
  $$

- rmse_2d_reproj_u, rmse_2d_reproj_v, rmse_2d_reproj_total: the errors obtained by reprojecting feature points using the calculated extrinsic parameters. In order, the u-coordinate error, v-coordinate error and total error in pixels.
